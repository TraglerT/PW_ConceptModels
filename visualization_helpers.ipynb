{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "### Codeblocks that can be added to Main.ipynb after the model has been trained to create misc visualizations and to analysis the data."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### Evaluation Area ###\n",
    "# Visualize the concepts\n",
    "\n",
    "index = 444\n",
    "image, true_label, true_concepts = derm7pt[index]\n",
    "image = image.to(device)\n",
    "\n",
    "# Get model predictions\n",
    "with torch.no_grad():\n",
    "    # to Note! this is the model from the last fold in the for loop\n",
    "    predicted_concepts, predicted_label = model(image)\n",
    "\n",
    "predicted_concepts = predicted_concepts.squeeze(0)\n",
    "predicted_concepts = predicted_concepts.to('cpu')\n",
    "image = image.to('cpu')\n",
    "\n",
    "\n",
    "# Plot\n",
    "plt.rcParams.update({'font.size' : 14})\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "concept_names = [name.replace('_num', '') for name in Derm7pt_data.model_columns['concepts']]\n",
    "concept_names = [name.replace('_', ' ') for name in concept_names]\n",
    "# image\n",
    "ax[0].imshow(image.squeeze().permute(1, 2, 0))\n",
    "ax[0].set_title(\"Input Image\")\n",
    "ax[0].axis('off')\n",
    "# True Concepts\n",
    "ax[1].barh(concept_names, true_concepts, color='mediumseagreen')\n",
    "ax[1].set_title(\"True Concepts\")\n",
    "ax[1].set_xlim(0, 1)\n",
    "ax[1].set_xlabel('Concept Value')\n",
    "# Predicted Concepts\n",
    "ax[2].barh(concept_names, predicted_concepts, color='dodgerblue')\n",
    "ax[2].set_title(\"Predicted Concepts\")\n",
    "ax[2].set_xlim(0, 1)\n",
    "ax[2].set_xlabel('Concept Value')\n",
    "# Adjust layout to make space for titles\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the image\n",
    "output_folder = 'output_Images'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_path = os.path.join(output_folder, f'concept_image_{index}.png')\n",
    "plt.savefig(output_path)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "print(predicted_label)\n"
   ],
   "id": "b27e9ea8342975a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:33:16.085723Z",
     "start_time": "2024-11-10T17:33:16.079240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Visualization of concepts, but True and predicted concepts are shown in same plot\n",
    "import numpy as np\n",
    "# Plot\n",
    "plt.rcParams.update({'font.size' : 16})\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "# Concept names\n",
    "concept_names = [name.replace('_num', '') for name in Derm7pt_data.model_columns['concepts']]\n",
    "concept_names = [name.replace('_', ' ') for name in concept_names]\n",
    "y_pos = np.arange(len(concept_names))\n",
    "\n",
    "# Image\n",
    "ax[0].imshow(image.squeeze().permute(1, 2, 0))\n",
    "ax[0].set_title(\"Input Image\")\n",
    "ax[0].axis('off')\n",
    "\n",
    "# Grouped bar chart for true and predicted concepts\n",
    "bar_width = 0.35  # Width of the bars\n",
    "\n",
    "# Plot true and predicted values side by side\n",
    "ax[1].barh(y_pos - bar_width/2, true_concepts, bar_width, label='True', color='mediumseagreen')\n",
    "ax[1].barh(y_pos + bar_width/2, predicted_concepts, bar_width, label='Predicted', color='dodgerblue')\n",
    "\n",
    "# Set the chart's labels and title\n",
    "ax[1].set_yticks(y_pos)\n",
    "ax[1].set_yticklabels(concept_names)\n",
    "ax[1].set_title(\"True vs Predicted Concepts\")\n",
    "ax[1].set_xlim(0, 1)  # Set limit for the x-axis (concept values)\n",
    "ax[1].set_xlabel('Concept Value')\n",
    "ax[1].legend()\n",
    "\n",
    "# Adjust layout to make space for titles\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the image\n",
    "output_folder = 'output_Images'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_path = os.path.join(output_folder, f'concept_image_grouped_{index}.png')\n",
    "plt.savefig(output_path)\n",
    "\n",
    "plt.show()\n"
   ],
   "id": "c3909264e2003d35",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Find examples for visualization\n",
    "def find_image_with_most_ones(indices, mode=\"val\"):\n",
    "    max_ones = 0\n",
    "    max_ones_index = -1\n",
    "\n",
    "    for idx in indices:\n",
    "        _, _, concepts = derm7pt[idx]\n",
    "        num_ones = torch.sum(concepts).item()  # Count the number of 1s in the concepts\n",
    "\n",
    "        if num_ones > max_ones:\n",
    "            max_ones = num_ones\n",
    "            max_ones_index = idx\n",
    "\n",
    "        if num_ones > 2:\n",
    "            print(f\"Found an image with {num_ones} ones in concepts in {mode} set: {idx}\")\n",
    "\n",
    "    return max_ones_index\n",
    "\n",
    "# Find the image with the most 1s in the concepts for both train and val sets\n",
    "train_max_ones_index = find_image_with_most_ones(train_idx, \"train\")\n",
    "val_max_ones_index = find_image_with_most_ones(val_idx)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Train set image index with the most 1s in concepts: {train_max_ones_index}\")\n",
    "print(f\"Validation set image index with the most 1s in concepts: {val_max_ones_index}\")\n"
   ],
   "id": "1291c38c5c3277ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# analyze connection of concept layer and label layer\n",
    "i = 0\n",
    "for layer in model.children():\n",
    "    i = i+1\n",
    "    if i == 10:\n",
    "        print(\"layer\", i)\n",
    "        weight = layer.state_dict()['weight']\n",
    "        bias = layer.state_dict()['bias']\n",
    "        print(\"weight: \", weight)\n",
    "        print(\"bias: \", bias)\n",
    "\n",
    "input_tensor = predicted_concepts\n",
    "print(\"input_tensor: \", input_tensor)\n",
    "input_tensor = input_tensor.to(device)\n",
    "output = torch.matmul(input_tensor, weight.T) + bias\n",
    "print(torch.softmax(output, 0))\n",
    "print(\"true label: \", derm7pt[89][1])"
   ],
   "id": "da02b8ee906eccd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:36:46.616449Z",
     "start_time": "2024-11-10T17:36:46.610930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# unfinshed visualization of concept -> label layer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Inputs from the second-to-last layer (7 inputs)\n",
    "input_tensor = np.array([1.4559e-01, 2.9092e-01, 2.6569e-03, 9.9728e-01, 9.8169e-01, 3.3091e-04, 3.8738e-05])\n",
    "\n",
    "# Weights for the final linear layer (for label 1)\n",
    "weights_label_1 = np.array([0.6878, 0.7810, 0.4819, 0.8467, -0.1470, 0.3153, 0.2474])\n",
    "\n",
    "# Bias for label 1\n",
    "bias_label_1 = 0.5086\n",
    "\n",
    "# Calculate the weighted contributions for label 1\n",
    "contributions_label_1 = input_tensor * weights_label_1\n",
    "\n",
    "# Sum of weighted contributions plus bias\n",
    "output_label_1 = np.sum(contributions_label_1) + bias_label_1\n",
    "\n",
    "# Visualization setup\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot input nodes as circles\n",
    "for i, input_value in enumerate(input_tensor):\n",
    "    ax.plot(0, i, 'go', markersize=10)  # Input nodes\n",
    "    ax.text(-0.2, i, f\"Input {i+1}\\n{input_value:.3f}\", va='center', ha='center', fontsize=10, color='green')\n",
    "\n",
    "# Plot the output node\n",
    "ax.plot(2, 3, 'bo', markersize=15)  # Output node\n",
    "ax.text(2.2, 3, f\"Output\\n{output_label_1:.3f}\", va='center', ha='left', fontsize=12, color='blue')\n",
    "\n",
    "# Draw arrows for each input to output with the weight labels\n",
    "for i, (input_value, weight, contribution) in enumerate(zip(input_tensor, weights_label_1, contributions_label_1)):\n",
    "    ax.arrow(0.1, i, 1.6, 3 - i, head_width=0.1, head_length=0.1, fc='gray', ec='gray')\n",
    "    ax.text(1, (i + 3) / 2, f\"{weight:.3f}\", ha='center', fontsize=10, color='black')\n",
    "\n",
    "# Add the bias as an arrow pointing directly to the output\n",
    "ax.arrow(1.2, 3.5, 0.8, -0.5, head_width=0.1, head_length=0.1, fc='blue', ec='blue')\n",
    "ax.text(1.8, 3.7, f\"Bias\\n{bias_label_1:.3f}\", ha='center', fontsize=10, color='blue')\n",
    "\n",
    "# Styling the plot\n",
    "ax.set_xlim(-1, 3)\n",
    "ax.set_ylim(-1, 7)\n",
    "ax.axis('off')  #\n"
   ],
   "id": "a41073ddd71440eb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d3ad4124b9f2f6d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
